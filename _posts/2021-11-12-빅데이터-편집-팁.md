---
title:  "[Code] 사이즈가 큰 데이터를 다루는 팁 모음"
excerpt: "법령정보센터 API 가져오는 코드에 관한 글입니다."

toc: true
toc_sticky: true
toc_label: "주요 목차"
 
date: 2021-11-09
last_modified_at: 2021-11-09

use_math: true
comments: true

categories:
  - ETC
---





- 데이터 사이즈 : 30만 건 이상의 딕셔너리로 구성된 리스트



## 📌 데이터 포맷 : 리스트 안의 딕셔너리 자체를 이용

- (상황) API로부터 최소 20만 건의 데이터를 받아야 함
- 처음에는 각 html 태그를 파싱하여 딕셔너리로 받고, 이것을 다시 pandas의 DataFrame 포맷으로 변환하여 저장함
- API 접속이 끊어질 때마다 손실되는 데이터 수를 줄이기 위해 데이터 저장에 들이는 시간을 줄이기로 함
- 아예 리스트 안에 여러 개의 딕셔너리로 데이터를 받아옴

```python
all_data = [{key1: value1, key2: value2, ...},
           {key1: value1, key2: value2, ...},
           {key1: value1, key2: value2, ...}, ...]
```





## 📌 데이터 셋 : pickle로 저장

- 위에서 받아온 데이터를 pickle 파일 포맷으로 저장함
- [pickle 참고문서](https://docs.python.org/3/library/pickle.html)
- pickle 형식은 파이썬에서 객체를 저장하는 파일 형식임
- 로딩이 매우 빨라서 큰 규모의 데이터를 다룰 때 편리함

```python
import pickle
 
# pickle 저장
with open("all_data.pickle","wb") as f:
    pickle.dump(all_data, f)
 
# pickle 불러오기
with open("./all_data.pickle","rb") as f:
    all_data = pickle.load(f)
```



## 📌 중복  제거 : 빠르게 하기 위해 문자열로 변환

- (문제) 리스트 안의 요소가 딕셔너리인 경우 set을 이용한 중복 제거가 불가능함
- (문제) remove, pop 등의 메서드를 이용한 요소 중복 제거는 시간이 너무 오래 걸림
- (해결) 각 딕셔너리를 문자열로 변환하여 중복 제거함
- 다른 방법보다 훨씬 빠르게 작동함

```python
def remove_duplicates(all_data):
	# 중복된 값 없이 각 요소를 저장할 set() 생성
    row = set()
    # 데이터 전체에 대하여 순회함
    for data in all_data:
        # 문자열로 변환한 데이터를 set()에 추가함
        row.add(str(data))
    return row
```

```python
# row에 담긴 값 확인
row = remove_duplicates(all_data)
>>>
{"{key1: value1, key2: value2, ...}",
"{key1: value1, key2: value2, ...}",
"{key1: value1, key2: value2, ...}", ...}
```

- (복구) 문자열로 변환된 요소를 다시 딕셔너리로 변환하고 싶은 경우, eval 메서드 이용함

```python
def restore_dataset(row):
	restore_data = []
    # row 안의 문자열에 대해 순회함
    for data in row:
        # 각 문자열에 대해 eval을 적용하면 따옴표를 제거한 코드 그대로 기능함
        restore_data.append(eval(data))
	return restore_data
```



## 📌 데이터 탐색 및 편집 : pandas의 DataFrame 이용

### 데이터 프레임 생성

```python
# 데이터프레임 생성
df = pd.DataFrame(restore_data)
```

### mask 활용

- pandas 라이브러리에 익숙해지면 필터링을 이용한 탐색이 편해짐
- ```DataFrame.loc[]```를 이용하는 것보다 mask를 이용한 탐색이 더 빠르게 처리되는 편임
- mask는 여러 개 중복하여 사용할 수 있음
- 🐥 pandas 소스코드 찾아보자. loc 함수에 for문이 포함되는 것 같음

```python
# mask 생성
mask = df['컬럼1'] == '특정값'
# mask 적용
df[mask]
```

### 데이터프레임에서 정규식 확인하기

```python
# pandas 각 행에서 특정 문자열 패턴이 포함되어 있는지 확인하는 방법
for string in strings:
    # 시리즈의 각 요소를 문자열로 받는 리스트에 대해
    all_titles = df['컬럼1'].str
    # 특정 문자열 패턴이
    pattern = r"^"+string+r".?등$"
    # 포함되어 있는지 여부를 mask로 생성함
    mask = all_titles.contains(pattern, regex=True).astype('boolean')
    # 해당 조건을 만족하는 경우의 데이터를 중복제거하고 리스트로 저장
    string_extend = df[mask]['데이터를 추출할 컬럼'].unique().tolist()
```

- 참고

  - ```pd.DataFrame.contains(pattern)```

  - DataFrame 안에 pattern이 존재하는지 반환함

  - regex=True로 해야 정규표현식을 인식

  - 일부 결측치는 NaN으로 dtype이 float이기 때문에, 컬럼을 mask로 이용하려면 ```astype()```을 이용하여 ```'boolean'``` 타입으로  변환하여 사용해야 함

    
