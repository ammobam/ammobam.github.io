---
title:  "[Code] 사이즈가 큰 데이터를 다루는 팁 모음"
excerpt: "법령정보센터 API 가져오는 코드에 관한 글입니다."

toc: true
toc_sticky: true
toc_label: "주요 목차"
 
date: 2021-11-09
last_modified_at: 2021-11-09

use_math: true
comments: true

categories:
  - ETC
---

- 문제가 된 데이터는 딕셔너리 30만 건을 포함한 리스트

```python
all_data = [{key1: value1, key2: value2, ...},
           {key1: value1, key2: value2, ...},
           {key1: value1, key2: value2, ...}, ...]
```



## 📌 중복 검사를 빠르게 하기 위해 문자열로 변환

- (문제) 리스트 안의 요소가 딕셔너리인 경우 set을 이용한 중복 제거가 불가능함
- (문제) remove, pop 등의 메서드를 이용한 요소 중복 제거는 시간이 너무 오래 걸림
- (해결) 각 딕셔너리를 문자열로 변환하여 중복 제거함
- 다른 방법보다 훨씬 빠르게 작동함

```python
def remove_duplicates(all_data):
	# 중복된 값 없이 각 요소를 저장할 set() 생성
    row = set()
    # 데이터 전체에 대하여 순회함
    for data in all_data:
        # 문자열로 변환한 데이터를 set()에 추가함
        row.add(str(data))
    return row
```

```python
# row에 담긴 값 확인
row = remove_duplicates(all_data)
>>>
{"{key1: value1, key2: value2, ...}",
"{key1: value1, key2: value2, ...}",
"{key1: value1, key2: value2, ...}", ...}
```

- (복구) 문자열로 변환된 요소를 다시 딕셔너리로 변환하고 싶은 경우, eval 메서드 이용함

```python
def restore_dataset(row):
	restore_data = []
    # row 안의 문자열에 대해 순회함
    for data in row:
        # 각 문자열에 대해 eval을 적용하면 따옴표를 제거한 코드 그대로 기능함
        restore_data.append(eval(data))
return restore_data
```



## 📌 사이즈가 큰 데이터는 pickle로 저장

## 📌 사이즈가 큰 데이터는 pandas보다 리스트 안의 딕셔너리 자체를 이용

