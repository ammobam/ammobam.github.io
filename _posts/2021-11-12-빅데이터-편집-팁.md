---
title:  "[Code] 사이즈가 큰 데이터를 다루는 팁 모음"
excerpt: "법령정보센터 API 가져오는 코드에 관한 글입니다."

toc: true
toc_sticky: true
toc_label: "주요 목차"
 
date: 2021-11-09
last_modified_at: 2021-11-09

use_math: true
comments: true

categories:
  - ETC
---





- 데이터 사이즈 : 30만 건 이상의 딕셔너리로 구성된 리스트



## 📌 데이터 포맷 : 리스트 안의 딕셔너리 자체를 이용

- (상황) API로부터 최소 20만 건의 데이터를 받아야 함
- 처음에는 각 html 태그를 파싱하여 딕셔너리로 받고, 이것을 다시 pandas의 DataFrame 포맷으로 변환하여 저장함
- API 접속이 끊어질 때마다 손실되는 데이터 수를 줄이기 위해 데이터 저장에 들이는 시간을 줄이기로 함
- 아예 리스트 안에 여러 개의 딕셔너리로 데이터를 받아옴

```python
all_data = [{key1: value1, key2: value2, ...},
           {key1: value1, key2: value2, ...},
           {key1: value1, key2: value2, ...}, ...]
```





## 📌 데이터 셋 : pickle로 저장

- 위에서 받아온 데이터를 pickle 파일 포맷으로 저장함
- [pickle 참고문서](https://docs.python.org/3/library/pickle.html)
- pickle 형식은 파이썬에서 객체를 저장하는 파일 형식임
- 로딩이 매우 빨라서 편리함

```python
import pickle
 
# pickle 저장
with open("all_data.pickle","wb") as f:
    pickle.dump(all_data, f)
 
# pickle 불러오기
with open("./all_data.pickle","rb") as f:
    all_data = pickle.load(f)
```



## 📌 중복  제거 : 빠르게 하기 위해 문자열로 변환

- (문제) 리스트 안의 요소가 딕셔너리인 경우 set을 이용한 중복 제거가 불가능함
- (문제) remove, pop 등의 메서드를 이용한 요소 중복 제거는 시간이 너무 오래 걸림
- (해결) 각 딕셔너리를 문자열로 변환하여 중복 제거함
- 다른 방법보다 훨씬 빠르게 작동함

```python
def remove_duplicates(all_data):
	# 중복된 값 없이 각 요소를 저장할 set() 생성
    row = set()
    # 데이터 전체에 대하여 순회함
    for data in all_data:
        # 문자열로 변환한 데이터를 set()에 추가함
        row.add(str(data))
    return row
```

```python
# row에 담긴 값 확인
row = remove_duplicates(all_data)
>>>
{"{key1: value1, key2: value2, ...}",
"{key1: value1, key2: value2, ...}",
"{key1: value1, key2: value2, ...}", ...}
```

- (복구) 문자열로 변환된 요소를 다시 딕셔너리로 변환하고 싶은 경우, eval 메서드 이용함

```python
def restore_dataset(row):
	restore_data = []
    # row 안의 문자열에 대해 순회함
    for data in row:
        # 각 문자열에 대해 eval을 적용하면 따옴표를 제거한 코드 그대로 기능함
        restore_data.append(eval(data))
	return restore_data
```



